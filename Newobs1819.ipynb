{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.table import Table\n",
    "from astropy import table\n",
    "from astropy.io import fits\n",
    "import astropy.units as u\n",
    "from astropy.time import Time\n",
    "from astropy.utils.exceptions import ErfaWarning\n",
    "from matplotlib import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sherpa.astro import ui\n",
    "import sherpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ChiantiPy.core as ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.set_conf_opt(\"sigma\", 1.645)\n",
    "ui.set_conf_opt(\"numcores\", 3)\n",
    "ui.set_xsabund(\"aspl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_E = 0.05\n",
    "line_energies = [(1.85, 'Si XIII'), (2.01, 'Si XIV'),\n",
    "                 (3.88, 'Ca XIX'), (4.11, 'Ca XX'),\n",
    "                 (6.7, 'Fe XXV'),\n",
    "                ]\n",
    "axranges = [(.5, 10.), (1.6, 2.2), (3.7, 4.3), (6, 7.2)]\n",
    "\n",
    "def specplot(plotfunc, figsize=None):\n",
    "    axes = []\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    axes.append(fig.add_subplot(2, 1, 1))\n",
    "    axes.append(fig.add_subplot(2, 3, 4))\n",
    "    axes.append(fig.add_subplot(2, 3, 5, sharey=axes[1]))\n",
    "    axes.append(fig.add_subplot(2, 3, 6, sharey=axes[1]))\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        plt.sca(ax)\n",
    "        plotfunc()\n",
    "        trans = transforms.blended_transform_factory(ax.transData, ax.transAxes)\n",
    "\n",
    "        for x in line_energies:\n",
    "            # Mark and label only lines in range\n",
    "            if (x[0] > axranges[i][0]) & (x[0] < axranges[i][1]):\n",
    "                ax.axvspan(x[0] - delta_E, x[0] + delta_E, facecolor='0.5', alpha=0.5)\n",
    "                # in top figure, not enough space\n",
    "                if i == 0:\n",
    "                    ax.text(x[0], 0.9, x[1].split(' ')[0], horizontalalignment='center',\n",
    "                        verticalalignment='center', transform=trans)\n",
    "                else:\n",
    "                    ax.text(x[0], 0.9, x[1], horizontalalignment='center',\n",
    "                        verticalalignment='center', transform=trans)\n",
    "        ax.set_title('')\n",
    "        ax.set_xlim(*axranges[i])\n",
    "        \n",
    "    axes[0].semilogy()\n",
    "    axes[0].set_ylim(1e-5, None)\n",
    "    for i in [2, 3]:\n",
    "        plt.setp(axes[i].get_yticklabels(), visible=False)\n",
    "        axes[i].set_ylabel('')\n",
    "        \n",
    "    for ax in axes[1:]:\n",
    "        zoom_effect(ax, axes[0], color='0.5')\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Table()\n",
    "data['ObsID'] = ['14539', '17644', '17764', '19980', '21176', '22323', '23100', '23102', '23101',\n",
    "                 '17764 + 19980', '22323+23100+23101+23102']\n",
    "data['filestem'] = list(data['ObsID'][:9]) + ['2017', '2019']\n",
    "data['filesrcB'] = list([ n + '_B_grp.pi' for n in data['ObsID'][:9]]) + ['2017_B_src.pi', '2019_B_src.pi']\n",
    "data['filebkgB'] = [ n + '_B_bkg.pi' for n in data['filestem']]\n",
    "data['filesrcA'] = [n.replace('B', 'A') for n in data['filesrcB']]\n",
    "data['filebkgA'] = [n.replace('B', 'A') for n in data['filebkgB']]\n",
    "data['year'] = [fits.getval('data/Chandra/' + n, 'DATE-OBS')[:4] for n in data['filesrcA'][:9]] + ['2017', '2019']\n",
    "\n",
    "plotorder = [0, 1, 9, 4, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move up, use data[year] for all plots\n",
    "mplcolors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "mplcolors = dict(zip(sorted(set(data['year'])), mplcolors))\n",
    "\n",
    "data['color'] = [mplcolors[r['year']] for r in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lcs(obsid, source):\n",
    "    lcall = Table.read('data/Chandra/{0}_{1}_lc.fits'.format(obsid, source), hdu=1)\n",
    "    lcsoft = Table.read('data/Chandra/{0}_{1}_lc_soft.fits'.format(obsid, source), hdu=1)\n",
    "    lchard = Table.read('data/Chandra/{0}_{1}_lc_hard.fits'.format(obsid, source), hdu=1)\n",
    "    lc = table.hstack([lcall, lcsoft, lchard], table_names=['all', 'soft', 'hard'], metadata_conflicts='silent')\n",
    "    # time columns are the same for each lightcurve, so remove dublicate entries here for simplicity\n",
    "    for c in lc.colnames:\n",
    "        if (('TIME' in c) or ('AREA' in c) or ('EXPOSURE' in c)) and ('all' in c):\n",
    "            lc.rename_column(c, c[:-4])\n",
    "            lc.remove_columns([c[:-4] + '_soft', c[:-4] + '_hard'])\n",
    "    ind  = lc['EXPOSURE'] > 0.\n",
    "    return lc[ind]\n",
    "    \n",
    "lccurves = [[ read_lcs(obsid, t) for t in ['srca', 'srcb']] for obsid in data['ObsID'][:-2]]\n",
    "for list1 in lccurves:\n",
    "    for lc in list1:\n",
    "        lc['t'] = lc['TIME'] - lc['TIME'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcaca = [Table.read('data/Chandra/monitor_{0}_lc.fit'.format(obsid), hdu=1)\n",
    "           for obsid in data['ObsID'][1:-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 13))\n",
    "\n",
    "nlc = len(lccurves)\n",
    "\n",
    "width = np.array([lc[0]['t'][-1] for lc in lccurves])\n",
    "width = width / width.sum() * 0.8  # last factor is scale factor to make space for label left of plot\n",
    "dy = [0.11, 0.11, 0.06]\n",
    "ypos = [0.1, 0.21, 0.32]\n",
    "axes = []\n",
    "for y in range(3):\n",
    "    for x in range(len(lccurves)):\n",
    "        kwargs = {}\n",
    "        if y != 0:\n",
    "            kwargs['sharex'] = axes[x]\n",
    "        if x != 0:\n",
    "            kwargs['sharey'] = axes[y * nlc]\n",
    "        axes.append(fig.add_axes((.1 + np.sum(width[0:x]) + x * 0.02, ypos[y], width[x], dy[y]), **kwargs))\n",
    "\n",
    "for j in range(3):\n",
    "    for i in range(1, nlc):\n",
    "        plt.setp(axes[j * nlc + i].get_yticklabels(), visible=False)\n",
    "        \n",
    "for j in [1, 2]:\n",
    "    for i in range(nlc):\n",
    "        plt.setp(axes[j * nlc + i].get_xticklabels(), visible=False)\n",
    "    \n",
    "for i, obsid in enumerate(data['ObsID'][:-2]):\n",
    "    axes[0 * nlc + i].errorbar(lccurves[i][0]['t']/1e3, lccurves[i][0]['NET_RATE_all'] * 1e3, lccurves[i][0]['ERR_RATE_all'] * 1e3, \n",
    "                             label='0.3-9.0 keV', color='b', lw=5, alpha=0.3)\n",
    "    axes[0 * nlc + i].plot(lccurves[i][0]['t']/1e3, lccurves[i][0]['NET_RATE_soft'] * 1e3, \n",
    "                         color='b', ls=':', label='0.3-1.0 keV')\n",
    "    axes[0 * nlc + i].plot(lccurves[i][0]['t']/1e3, lccurves[i][0]['NET_RATE_hard'] * 1e3, \n",
    "                         color='b', ls='--', label='1.0-9.0 keV')\n",
    "    axes[1 * nlc + i].errorbar(lccurves[i][1]['t']/1e3, lccurves[i][1]['NET_RATE_all'] * 1e3, lccurves[i][1]['ERR_RATE_all'] * 1e3,\n",
    "                             label='0.3-9.0 keV', color='g', lw=5, alpha=0.3)\n",
    "    axes[1 * nlc + i].plot(lccurves[i][1]['t']/1e3, lccurves[i][1]['NET_RATE_soft'] * 1e3, \n",
    "                         color='g', ls=':', label='0.3-1.0 keV')\n",
    "    axes[1 * nlc + i].plot(lccurves[i][1]['t']/1e3, lccurves[i][1]['NET_RATE_hard'] * 1e3, \n",
    "                     color='g', ls='--', label='1.0-9.0 keV')\n",
    "    axes[2 * nlc + i].set_title(obsid)\n",
    "    # ACA data\n",
    "    if i > 0:\n",
    "        axes[2 * nlc + i].plot((lcaca[i - 1]['time'] - lcaca[i - 1]['time'][0]) / 1e3, lcaca[i - 1]['mag'], color='k')\n",
    "   \n",
    "axes[2 * nlc].invert_yaxis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obsid in data['ObsID'][:-2]:\n",
    "    lcall = Table.read('data/Chandra/{0}_{1}_lc.fits'.format(obsid, 'srca'), hdu=1)\n",
    "    print(obsid, np.sum(lcall['COUNTS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for row in data:\n",
    "    ui.load_data(row['filestem'] + '_B', 'data/Chandra/' + row['filesrcB'])\n",
    "    ui.load_bkg(row['filestem'] + '_B', 'data/Chandra/' + row['filebkgB'])                  \n",
    "    ui.load_data(row['filestem'] + '_A', 'data/Chandra/' + row['filesrcA'])\n",
    "    ui.load_bkg(row['filestem'] + '_A', 'data/Chandra/' + row['filebkgA'])                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.notice(None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.get_filter('22323_A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in ui.list_data_ids():\n",
    "    ui.group_width(o, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ui.set_analysis('energy')\n",
    "ui.ignore(None, 0.3)\n",
    "ui.ignore(9., None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.get_filter('22323_A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AAVSO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aavso = Table.read('data/aavso.txt', format='ascii.csv', fill_values = ('N/A', 0))\n",
    "# Sometimes the Magnitude column contains the \"<\" sing for upper limits.\n",
    "aavso['Mag'] = np.zeros(len(aavso))\n",
    "for i in range(len(aavso)):\n",
    "    try:\n",
    "        aavso['Mag'][i] = float(aavso['Magnitude'][i])\n",
    "    except ValueError:\n",
    "        aavso['Mag'][i] = np.ma.masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = dict([('Vis.', {'color': (1., 0.5, 1.), 'marker': '.'}),\n",
    "                     ('B', {'color': 'b', 'marker': 'p'}),\n",
    "                     ('V', {'color': 'g', 'marker': 'o'}),\n",
    "                     ('R', {'color': 'r', 'marker': '*'}),\n",
    "                     ('ACA', {'color': 'k', 'marker': 'D', 'markersize': 7})\n",
    "                    ])\n",
    "def plotaavso(ax):\n",
    "    for band in bands:\n",
    "        ind = (aavso['Band'] == band)\n",
    "        ax.plot(aavso['JD'][ind]-2400000.5, aavso['Mag'][ind], linestyle='None', **bands[band], label=band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obstimes = np.array([[Time(lc[0]['TIME_MIN'][0], format='cxcsec').mjd, \n",
    "             Time(lc[0]['TIME_MAX'][-1], format='cxcsec').mjd] for lc in lccurves])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Chandra ACA magnitudes\n",
    "for l in lcaca:\n",
    "    aavso.add_row({'JD': Time(l['time'].mean(), format='cxcsec').jd, 'Mag': l['mag'].mean(), 'Band': 'ACA'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def years(tmjd):\n",
    "    return Time(tmjd, format='mjd').decimalyear\n",
    "\n",
    "def update_axyears(ax):\n",
    "   y1, y2 = ax.get_xlim()\n",
    "   axy.set_xlim(years(y1), years(y2))\n",
    "   ax.figure.canvas.draw()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "axy = ax.twiny()\n",
    "# automatically update ylim of ax2 when ylim of ax1 changes.\n",
    "ax.callbacks.connect(\"xlim_changed\", update_axyears)\n",
    "\n",
    "plotaavso(ax)\n",
    "ax.set_xlim([56000, 59000])\n",
    "ax.invert_yaxis()\n",
    "\n",
    "ax.eventplot(obstimes[:, 0], colors=['k'], lineoffsets=[9],\n",
    "                    linelengths=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator, MultipleLocator\n",
    "    \n",
    "from matplotlib.transforms import Bbox, TransformedBbox, \\\n",
    "    blended_transform_factory, Affine2D\n",
    "\n",
    "from mpl_toolkits.axes_grid1.inset_locator import BboxPatch, BboxConnector,\\\n",
    "    BboxConnectorPatch\n",
    "\n",
    "# code for zoom effects taken and modified from http://matplotlib.org/users/annotations_guide.html\n",
    "def connect_bbox(bbox1, bbox2,\n",
    "                 loc1a, loc2a, loc1b, loc2b,\n",
    "                 prop_lines, prop_patches=None):\n",
    "    if prop_patches is None:\n",
    "        prop_patches = prop_lines.copy()\n",
    "        prop_patches[\"alpha\"] = prop_patches.get(\"alpha\", 1)*0.2\n",
    "\n",
    "    c1 = BboxConnector(bbox1, bbox2, loc1=loc1a, loc2=loc2a, **prop_lines)\n",
    "    c1.set_clip_on(False)\n",
    "    c2 = BboxConnector(bbox1, bbox2, loc1=loc1b, loc2=loc2b, **prop_lines)\n",
    "    c2.set_clip_on(False)\n",
    "\n",
    "    bbox_patch1 = BboxPatch(bbox1, **prop_patches)\n",
    "    bbox_patch2 = BboxPatch(bbox2, **prop_patches)\n",
    "\n",
    "    p = BboxConnectorPatch(bbox1, bbox2,\n",
    "                           # loc1a=3, loc2a=2, loc1b=4, loc2b=1,\n",
    "                           loc1a=loc1a, loc2a=loc2a, loc1b=loc1b, loc2b=loc2b,\n",
    "                           **prop_patches)\n",
    "    p.set_clip_on(False)\n",
    "\n",
    "    return c1, c2, bbox_patch1, bbox_patch2, p\n",
    "\n",
    "\n",
    "def zoom_effect(ax1, ax2, xtrans=Affine2D(), **kwargs):\n",
    "    \"\"\"\n",
    "    ax1 : the main axes\n",
    "    ax2 : the zoomed axes\n",
    "\n",
    "    connect ax1 & ax2. The x-range of (xmin, xmax) in both axes will\n",
    "    be marked.  The keywords parameters will be used ti create\n",
    "    patches. The xmin & xmax will be taken from the\n",
    "    ax1.viewLim.\n",
    "    \"\"\"\n",
    "\n",
    "    tt = ax1.transScale + (ax1.transLimits + ax2.transAxes)\n",
    "    trans = blended_transform_factory(xtrans + ax2.transData, tt)\n",
    "\n",
    "    mybbox1 = ax1.bbox\n",
    "    mybbox2 = TransformedBbox(ax1.viewLim, trans)\n",
    "\n",
    "    prop_patches = kwargs.copy()\n",
    "    prop_patches[\"ec\"] = \"none\"\n",
    "    prop_patches[\"alpha\"] = 0.2\n",
    "\n",
    "    # The inversion messes up the coner points.\n",
    "    # This is tweaked for inverted axes.\n",
    "    # I'm sure ther is some clever way to use the right transforms for the y axis \n",
    "    # to take care of that automatically, but for \n",
    "    # a one-off script it's much simpler to just adjust the corners by hand.\n",
    "    if ax1.yaxis_inverted():\n",
    "        loc2a = 2\n",
    "        loc2b = 1\n",
    "    else:\n",
    "        loc2a = 3\n",
    "        loc2b = 4\n",
    "    \n",
    "    c1, c2, bbox_patch1, bbox_patch2, p = \\\n",
    "        connect_bbox(mybbox1, mybbox2,\n",
    "                     loc1a=2, loc2a=loc2a, loc1b=1, loc2b=loc2b,\n",
    "                     prop_lines=kwargs, prop_patches=prop_patches)\n",
    "\n",
    "    #ax1.add_patch(bbox_patch1)\n",
    "    ax2.add_patch(bbox_patch2)\n",
    "    ax2.add_patch(c1)\n",
    "    ax2.add_patch(c2)\n",
    "    ax2.add_patch(p)\n",
    "\n",
    "    return c1, c2, bbox_patch1, bbox_patch2, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsids = data['ObsID'][:-2]\n",
    "n_obsids = len(obsids)\n",
    "year = np.array(list(set([int(y) for y in data['year']])))\n",
    "year.sort()\n",
    "n_years = len(year)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 13))\n",
    "ax00 = fig.add_subplot(511)\n",
    "ax11 = fig.add_subplot(512)\n",
    "\n",
    "n_years = len(set(data['year']))\n",
    "axrow2 = [fig.add_subplot(5, n_years, 2 * n_years + 1)]\n",
    "for i in range(2, n_years+1):\n",
    "    axrow2.append(fig.add_subplot(5, n_years, 2 * n_years + i, sharey=axrow2[0]))\n",
    "\n",
    "# Set up second x-axis for top plot that is labeled in years\n",
    "ax00years = ax00.twiny()\n",
    "ax11years = ax11.twiny()\n",
    "\n",
    "def years(tmjd):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore', ErfaWarning)\n",
    "        t = Time(tmjd, format='mjd').decimalyear\n",
    "    return t\n",
    "\n",
    "def update_ax11years(ax11):\n",
    "   y1, y2 = ax11.get_xlim()\n",
    "   ax11years.set_xlim(years(y1), years(y2))\n",
    "   ax11.figure.canvas.draw()\n",
    "\n",
    "def update_ax00years(ax00):\n",
    "   y1, y2 = ax00.get_xlim()\n",
    "   ax00years.set_xlim(years(y1), years(y2))\n",
    "   ax00.figure.canvas.draw()\n",
    "\n",
    "# automatically update ylim of ax2 when ylim of ax1 changes.\n",
    "ax00.callbacks.connect(\"xlim_changed\", update_ax00years)\n",
    "ax11.callbacks.connect(\"xlim_changed\", update_ax11years)\n",
    "\n",
    "for ax in fig.axes:\n",
    "    plotaavso(ax)\n",
    "    \n",
    "for ax in fig.axes:\n",
    "    for i in range(obstimes.shape[0]):\n",
    "        ax.bar(obstimes[i, 0], height=10, width=obstimes[i, 1]-obstimes[i, 0], bottom=8, align='edge', \n",
    "               color='0.5', edgecolor='0.5')\n",
    "\n",
    "ax00.invert_yaxis()\n",
    "ax11.invert_yaxis()\n",
    "ax00.set_xlim([52000, 59000])\n",
    "ax11.set_xlim([56200, 59000])\n",
    "\n",
    "dtime = 15.\n",
    "for i, y in enumerate(year):\n",
    "    meanmjd = np.mean(obstimes[data['year'][:-2] == str(y)])\n",
    "    axrow2[i].set_xlim(meanmjd - dtime, meanmjd + dtime)\n",
    "    axrow2[i].get_xaxis().get_major_formatter().set_useOffset(False)\n",
    "    axrow2[i].xaxis.set_major_locator( MaxNLocator(nbins=3, steps=[5, 10]) )\n",
    "    if i > 0:\n",
    "        plt.setp(axrow2[i].get_yticklabels(), visible=False)\n",
    "    #axrow2[i].set_title(y)\n",
    "        \n",
    "axrow2[0].invert_yaxis()\n",
    "\n",
    "ax00.legend(numpoints=1, loc='lower left')\n",
    "ax11.set_ylabel('mag')\n",
    "ax21.set_ylabel('mag')\n",
    "ax22.set_xlabel('time [MJD]')\n",
    "ax00years.set_xlabel('time [years]')\n",
    "\n",
    "axrow2[0].set_ylim([13.5, 9])\n",
    "ax11.set_ylim([15, 9])\n",
    "ax00.set_ylim([15, 9])\n",
    "\n",
    "width = np.array([lc[0]['t'][-1] for lc in lccurves])\n",
    "width = width / width.sum() * 0.7  # last factor is scale factor to make space for label left of plot\n",
    "dy = [0.11, 0.11, 0.06]\n",
    "ypos = [0.1, 0.21, 0.32]\n",
    "axes = []\n",
    "\n",
    "\n",
    "for y in range(3):\n",
    "    for x in range(n_obsids):\n",
    "        kwargs = {}\n",
    "        if y != 0:\n",
    "            kwargs['sharex'] = axes[x]\n",
    "        if x != 0:\n",
    "            kwargs['sharey'] = axes[y * n_obsids]\n",
    "        axes.append(fig.add_axes((.1 + np.sum(width[0:x]) + x * 0.02, ypos[y], width[x], dy[y]), **kwargs))\n",
    "        \n",
    "for j in range(3):\n",
    "    for i in range(1, n_obsids):\n",
    "        plt.setp(axes[j * n_obsids + i].get_yticklabels(), visible=False)\n",
    "        \n",
    "for j in [1, 2]:\n",
    "    for i in range(n_obsids):\n",
    "        plt.setp(axes[j * n_obsids + i].get_xticklabels(), visible=False)\n",
    "\n",
    "for i, obsid in enumerate(obsids):\n",
    "    axes[0 * n_obsids + i].errorbar(lccurves[i][0]['t']/1e3, lccurves[i][0]['NET_RATE_all'] * 1e3, lccurves[i][0]['ERR_RATE_all'] * 1e3, \n",
    "                             label='0.3-9.0 keV', color='b', lw=5, alpha=0.3)\n",
    "    axes[0 * n_obsids + i].plot(lccurves[i][0]['t']/1e3, lccurves[i][0]['NET_RATE_soft'] * 1e3, \n",
    "                         color='b', ls=':', label='0.3-1.0 keV')\n",
    "    axes[0 * n_obsids + i].plot(lccurves[i][0]['t']/1e3, lccurves[i][0]['NET_RATE_hard'] * 1e3, \n",
    "                         color='b', ls='--', label='1.0-9.0 keV')\n",
    "    axes[1 * n_obsids + i].errorbar(lccurves[i][1]['t']/1e3, lccurves[i][1]['NET_RATE_all'] * 1e3, lccurves[i][1]['ERR_RATE_all'] * 1e3,\n",
    "                             label='0.3-9.0 keV', color='g', lw=5, alpha=0.3)\n",
    "    axes[1 * n_obsids + i].plot(lccurves[i][1]['t']/1e3, lccurves[i][1]['NET_RATE_soft'] * 1e3, \n",
    "                         color='g', ls=':', label='0.3-1.0 keV')\n",
    "    axes[1 * n_obsids + i].plot(lccurves[i][1]['t']/1e3, lccurves[i][1]['NET_RATE_hard'] * 1e3, \n",
    "                     color='g', ls='--', label='1.0-9.0 keV')\n",
    "    #axes[2 * 4 + i].set_title(obsid)\n",
    "    if i > 0:\n",
    "        axes[2 * n_obsids + i].plot((lcaca[i-1]['time'] - lccurves[i][0]['TIME'][0]) / 1e3, # Subtract 0 point of X-ray lc\n",
    "                                    lcaca[i - 1]['mag'], color='k')\n",
    "    \n",
    "#axes[n_obsids * 2].yaxis.set_major_locator( MaxNLocator(nbins=4) )\n",
    "axes[8].legend()\n",
    "axes[n_obsids * 2].invert_yaxis()\n",
    "# axes[n_obsids + 8].legend()\n",
    "axes[0].set_ylabel('              net X-ray counte rate [cts/ks]')\n",
    "axes[4].set_xlabel('time from beginning of observation [ks]')\n",
    "axes[n_obsids * 2].set_ylabel('ACA [mag]')\n",
    "axes[n_obsids].text(0., 60., 'RW Aur B')\n",
    "axes[0].text(0, 2., 'RW Aur A')\n",
    "axes[n_obsids * 2].text(0, 11.1, 'RW Aur A + B\\n(unresolved)')\n",
    "axes[n_obsids * 2].text(0, 12, 'no ACA data', color='0.5')\n",
    "#axes[n_obsids * 2].text(35., 11, '2013-Jan')\n",
    "#axes[n_obsids * 2 + 1].text(15, 11., '2015-Apr')\n",
    "#axes[n_obsids * 2 + 2].text(15, 11.5, '2017-Jan-09')\n",
    "#axes[n_obsids * 2 + 3].text(-2, 11.5, '2017\\nJan-11')\n",
    "\n",
    "zoom_effect(ax11, ax00, color='0.5')\n",
    "for ax in axrow2:\n",
    "    zoom_effect(ax, ax11, color='0.5')\n",
    "for i in range(n_obsids):\n",
    "    zoom_effect(axes[2 * n_obsids + i], axrow2[np.nonzero(year == int(data['year'][i]))[0][0]], \n",
    "                xtrans=Affine2D.from_values(1./(24*3600/1000), 0, 0, 1, obstimes[i, 0], 0), color='0.5')\n",
    "               \n",
    "                   \n",
    "fig.subplots_adjust(wspace=0.02, hspace=.35, left=0.1, right=0.95)\n",
    "\n",
    "#fig.savefig(os.path.join(figout, 'lc.pdf'), bbox_inches='tight')\n",
    "#fig.savefig(os.path.join(figout, 'lc.png'), bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The spectrum of RW Aur B\n",
    "This needs tobe modeled, because we will use it as a component in the RW Aur A model to account for the contamination of the RW Aur A data by signal coming from RW Aur B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in ui.list_data_ids():\n",
    "    if i[-2:] == '_B':\n",
    "        ui.group_counts(i, 15)\n",
    "    \n",
    "for i in plotorder:\n",
    "    ui.plot_data(data['filestem'][i] + '_B', overplot=True, color=data['color'][i])\n",
    "    \n",
    "ax = plt.gca()\n",
    "ax.loglog()\n",
    "ax.set_xlim(.4, 6)\n",
    "ax.set_ylim(2e-4, 0.1)\n",
    "ax.legend(ax.get_lines(), data['year'][plotorder])\n",
    "ax.set_title('RW Aur B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(set(data['year']))\n",
    "years.sort()\n",
    "\n",
    "b_models = {y: ui.xsphabs(name='Ba_'+y) * (ui.xsvapec(name='Bv1_'+y) + ui.xsvapec(name='Bv2_'+y)) for y in years}\n",
    "\n",
    "for row in data:\n",
    "    ui.set_source(row['filestem'] + '_B', b_models[row['year']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bo in b_models.values():\n",
    "    for elem in ['C', 'N', 'O','Ne', 'Fe', 'Si', 'Mg']:\n",
    "        setattr(bo.rhs.rhs, elem, getattr(bo.rhs.lhs, elem))\n",
    "    bo.rhs.lhs.kT = 0.5\n",
    "    bo.rhs.rhs.kT = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.show_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fit_B = [row['filestem']+'_B' for row in data if row['filestem']==row['ObsID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Leaving these independent can actually lead to the worse chi^2, so no reason to suspect that nH is changeing\n",
    "# Fix to reduce number of parameters in fit\n",
    "\n",
    "for y in years[1:]:\n",
    "    b_models[y].lhs.nH = b_models[years[0]].lhs.nH\n",
    "\n",
    "ui.fit(*to_fit_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data:\n",
    "    ui.subtract(row['filestem']+'_B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# It seems that joining the temperature of both components should work well\n",
    "for y in years[1:]:\n",
    "    b_models[y].rhs.lhs.kT = b_models[years[0]].rhs.lhs.kT\n",
    "    b_models[y].rhs.rhs.kT = b_models[years[0]].rhs.rhs.kT\n",
    "    \n",
    "ui.fit(*to_fit_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spectra are so remarkebly similar, it's almost uncanning, given the change in flux that I see in the lightcurve. It seems that all the variability I see within one observation washes out when I add the data from the entire observation together. It might actually we worth investigating, if there are any changes at all! The norms are significantly different, though.\n",
    "\n",
    "I tried freeing abundances, but this is so close to defaults, there really is no reason to set them to anything else than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following line to change the size of the figure\n",
    "# fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "for i,j  in enumerate(plotorder):\n",
    "    ui.plot_fit(data['filestem'][j] + '_B', overplot=not (i==0), color=data['color'][j])\n",
    "    \n",
    "ax = plt.gca()\n",
    "ax.loglog()\n",
    "ax.set_xlim(.4, 6)\n",
    "ax.set_ylim(2e-4, 0.1)\n",
    "ax.legend(ax.get_lines()[::2], data['year'][plotorder])\n",
    "ax.set_title('RW Aur B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following line to change the size of the figure\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "for i,j  in enumerate(plotorder):\n",
    "    ui.plot_bkg(data['filestem'][j] + '_B', overplot=not (i==0), color=data['color'][j])\n",
    "    \n",
    "ax = plt.gca()\n",
    "ax.loglog()\n",
    "ax.set_xlim(.4, 9)\n",
    "ax.set_ylim(1e-5, 0.01)\n",
    "ax.legend(ax.get_lines(), data['year'][plotorder])\n",
    "ax.set_title('Bkg for RW Aur B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The PSF of RW Aur B\n",
    "\n",
    "Te PSF might be different from observation to observation for several reasons. In particular, the ACA monitoring may lead to a degradation of the PSF. A larger PSF means that more photons from RW Aur B will contaminate the extraction region of RW Aur A. Thus, I first try to get a quantitative measure of the PSF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "radprofs = [Table.read('data/Chandra/{0}_rprofile.fits'.format(o), hdu=1) for o in data['filestem'][:-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in radprofs:\n",
    "    plt.semilogy(r['SUR_BRI'] / r['SUR_BRI'][0], label=r.meta['OBS_ID'])\n",
    "plt.ylim(.001, 1)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observations taken in 2019 (22323, 23100, 23101, 23102) are significantly above the olders ones in annulus 3-6, which is the area overlapping with source A and the area in which we calculate the background for A. It's not much in absolute terms, but it cearly means that the scaling factor between B spectrum as background for A must be different in 2019 and the previous years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The spectrum of RW Aur A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plt.figure(figsize=(12, 10))\n",
    "for i in ui.list_data_ids():\n",
    "    if i[-2:] == '_A':\n",
    "        ui.group_counts(i, 5)\n",
    "    \n",
    "for i in plotorder:\n",
    "    ui.plot_data(data['filestem'][i] + '_A', overplot=not(i==plotorder[0]), color=data['color'][i])\n",
    "    \n",
    "ax = plt.gca()\n",
    "ax.loglog()\n",
    "ax.set_xlim(.5, 9)\n",
    "ax.set_ylim(5e-5, 0.04)\n",
    "ax.legend(ax.get_lines(), data['year'][plotorder])\n",
    "ax.set_title('RW Aur A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.get_filter('22323_A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fit_A = [row['filestem']+'_A' for row in data if row['filestem']==row['ObsID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleB_early = ui.scale1d(name='scaleB_early')\n",
    "scaleB_2019 = ui.scale1d(name='scaleB_2019')\n",
    "\n",
    "scaleB = {'2013': scaleB_early, '2015': scaleB_early, '2017': scaleB_early, '2018': scaleB_early, \n",
    "          '2019': scaleB_2019}\n",
    "\n",
    "# Freeze everything in B models except the scale\n",
    "for row in data:\n",
    "    b_mod = b_models[row['year']]\n",
    "    ui.set_bkg_source(row['filestem'] + '_A', scaleB[row['year']] * b_mod)\n",
    "    \n",
    "    for model in [b_mod.lhs, b_mod.rhs.lhs, b_mod.rhs.rhs]:\n",
    "        for par in model.pars:\n",
    "            par.frozen=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the 2019 datasets have too few counts to make a fit at all. So, use merged dataset here.\n",
    "# If the count numbers are so small, the error is dominated by counting statistics and not by systematics\n",
    "# of coadding spectra.\n",
    "\n",
    "# Can revisit this after I find where all the counts went.\n",
    "ui.fit_bkg('14539_A', '17644_A', '2017_A', '21176_A', '2019_A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following line to change the size of the figure\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "for i,j  in enumerate(plotorder):\n",
    "    ui.plot_bkg_fit(data['filestem'][j] + '_A', overplot=not (i==0), color=data['color'][j])\n",
    "    \n",
    "ax = plt.gca()\n",
    "ax.loglog()\n",
    "#ax.set_xlim(.4, 9)\n",
    "ax.set_ylim(1e-6, 0.01)\n",
    "ax.legend(ax.get_lines()[::2], data['year'][plotorder])\n",
    "ax.set_title('Bkg for RW Aur A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I see that the background is described quite well in the early observations, but, even with the higher scaling factor for 2019, the 2019 background is significantly underpredicted on the soft end. That will cause an apparent soft component in the RW Aur A model, that in trouth is just the background. What's surprising is that the shape of the observed background spectrum has not changed at all. ACIS contamination should reduce the number of soft counts detected (and it does in the RW Aur B spectrum), so why is the number of soft counts not going down here? The rate is far too high to be explained with particle background. Is the soft PSF so much wider than the hard PSF?\n",
    "\n",
    "While an answer would be good, really what I need is a model that describes the background well enough so I can carry on with fitting. On the other hand, I'm reluctant to introduce a new component that's fit to just a few bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ['22323_A', '23100_A', '23101_A', '23102_A'] #, '2019_A']\n",
    "for o in ids:\n",
    "    ui.plot_bkg_fit(o, overplot=True)\n",
    "ax = plt.gca()\n",
    "ax.loglog()\n",
    "#ax.set_xlim(.4, 9)\n",
    "#ax.set_ylim(1e-5, 0.01)\n",
    "ax.legend(ax.get_lines()[::2], ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data:\n",
    "    ui.unsubtract(row['filestem']+'_B')\n",
    "\n",
    "for o in ui.list_data_ids():\n",
    "    ui.group_width(o, 1)\n",
    "    ui.set_analysis(o, \"bin\", \"counts\", 0)\n",
    "    pl = ui.get_data_plot(o)\n",
    "    pl1 = ui.get_bkg_plot(o)\n",
    "    print('{}: {} - {}'.format(o, pl.y.sum(), pl1.y.sum()))\n",
    "    \n",
    "ui.set_analysis(\"energy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleB_early.c0.frozen = True\n",
    "scaleB_2019.c0.frozen = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line-diagnostics\n",
    "Of course, we do not really resolve individual lines in ACIS spectra, but below it looks like I should. So, at the very least, I can use CHIANTI to see H/He-like line ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logtemp = np.arange(5.8, 8.5, .1)\n",
    "temp = 10**logtemp\n",
    "\n",
    "def intensityHHe(temp, Hion, Heion):\n",
    "    Helike = ch.ion(Heion, temperature=temp, eDensity=1.e+9, em=1.e+27)\n",
    "    Helike.intensity()\n",
    "    Hlike = ch.ion(Hion, temperature=temp, eDensity=1.e+9, em=1.e+27)\n",
    "    Hlike.intensity()\n",
    "\n",
    "    e_r = Helike.Intensity['intensity'][:, (Helike.Intensity['lvl1'] == 1) & (Helike.Intensity['pretty2'] == '1s.2p 1P1.0')].flatten()\n",
    "    e_i1 = Helike.Intensity['intensity'][:, (Helike.Intensity['lvl1'] == 1) & (Helike.Intensity['pretty2'] == '1s.2p 3P2.0')].flatten()\n",
    "    e_i2 = Helike.Intensity['intensity'][:, (Helike.Intensity['lvl1'] == 1) & (Helike.Intensity['pretty2'] == '1s.2p 3P1.0')].flatten()\n",
    "    e_f = Helike.Intensity['intensity'][:, (Helike.Intensity['lvl1'] == 1) & (Helike.Intensity['pretty2'] == '1s.2s 3S1.0')].flatten()\n",
    "\n",
    "    e_lya1 = Hlike.Intensity['intensity'][:, (Hlike.Intensity['lvl1'] == 1) & (Hlike.Intensity['pretty2'] == '2s 2S0.5')].flatten()\n",
    "    e_lya2 = Hlike.Intensity['intensity'][:, (Hlike.Intensity['lvl1'] == 1) & (Hlike.Intensity['pretty2'] == '2p 2P0.5')].flatten()\n",
    "    e_lya3 = Hlike.Intensity['intensity'][:, (Hlike.Intensity['lvl1'] == 1) & (Hlike.Intensity['pretty2'] == '2p 2P1.5')].flatten()\n",
    "    \n",
    "    return e_lya1 + e_lya2 + e_lya3, e_r + e_i1 + e_i2 + e_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "axt = ax.twinx()\n",
    "    \n",
    "for Heion, Hion, color in ([('ne_9', 'ne_10', 'b'), ('si_13', 'si_14', 'r'), ('ca_19', 'ca_20', 'g')]):\n",
    "    e_H, e_He = intensityHHe(temp, Hion, Heion)\n",
    "\n",
    "    ax.semilogx(temp, e_H / np.max(e_He), color=color)\n",
    "    ax.semilogx(temp, e_He / np.max(e_He), color=color, ls=':')\n",
    "\n",
    "    axt.semilogy(temp, e_H / e_He, color=color, lw=5, alpha=.5)\n",
    "\n",
    "#ax.loglog()\n",
    "axt.set_ylim(0.1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_models = {y: ui.xsphabs(name='Aa_'+y) * (ui.xsvapec(name='Av1_'+y) + ui.xsvapec(name='Av2_'+y)) for y in years}\n",
    "\n",
    "for row in data:\n",
    "    a_mod = a_models[row['year']]\n",
    "    ui.set_source(row['filestem'] + '_A', a_mod)\n",
    "    for elem in ['C', 'N', 'O','Ne', 'Mg', 'Al', 'Si', 'S', 'Ar', 'Ca', 'Fe', 'Ni']:\n",
    "        setattr(a_mod.rhs.rhs, elem, getattr(a_mod.rhs.lhs, elem))\n",
    "    a_mod.lhs.nH.frozen = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ui.list_data_ids():\n",
    "    if i[-2:] == '_A':\n",
    "        try:\n",
    "            ui.ungroup(i)\n",
    "        except sherpa.utils.err.DataErr:\n",
    "            # It's already ungrouped\n",
    "            pass\n",
    "ui.set_stat('cash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2013 - 2017\n",
    "This is the data that is covered in previous publications already, so the fits here are mostly reproducing the models published there. I could just hardcode the numbers from the previous fits, but for now I actually run the fits again. Results look consistent, but I should probably check again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of kT=20 from Skinner & Guedel for 2013 data, fix kT as in Schneider et al for 2015 data\n",
    "a_models['2013'].rhs.lhs.Ne.frozen = False\n",
    "a_models['2013'].rhs.lhs.Fe.frozen = False\n",
    "a_models['2013'].rhs.rhs.kT.frozen = True\n",
    "a_models['2013'].rhs.rhs.kT = 20.\n",
    "\n",
    "a_models['2015'].rhs.lhs.kT = a_models['2013'].rhs.lhs.kT\n",
    "a_models['2015'].rhs.rhs.kT = a_models['2013'].rhs.rhs.kT\n",
    "\n",
    "a_models['2017'].rhs.lhs.Fe.frozen = False\n",
    "a_models['2017'].rhs.rhs.kT.frozen = True\n",
    "a_models['2017'].rhs.rhs.kT = 20.\n",
    "\n",
    "# Set models close to final to speed up convergence when running the notebook again\n",
    "# This also redues the risk of running the fit into non-sensical minimums as I observed\n",
    "# several times when I experimented with different binning, statistics etc.\n",
    "a_models['2013'].lhs.nH = 0.3\n",
    "a_models['2013'].rhs.lhs.kT = 0.4\n",
    "a_models['2013'].rhs.lhs.norm = 1e-4\n",
    "a_models['2013'].rhs.rhs.norm = 4e-5\n",
    "\n",
    "a_models['2017'].lhs.nH = 45\n",
    "a_models['2017'].rhs.lhs.kT = 1\n",
    "a_models['2017'].rhs.lhs.Fe = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.ignore(None, .4)\n",
    "ui.ignore(8., None)\n",
    "        \n",
    "ui.fit('14539_A')\n",
    "#ui.fit('17644_A')\n",
    "ui.fit('17764_A', '19980_A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze parameters that we want to take from the 2013 fit at the values\n",
    "# fitted above to the 2013 data\n",
    "a_models['2015'].rhs.lhs.kT.frozen = True\n",
    "a_models['2015'].rhs.rhs.kT.frozen = True\n",
    "a_models['2015'].rhs.lhs.kT = a_models['2013'].rhs.lhs.kT\n",
    "a_models['2015'].rhs.rhs.kT = a_models['2013'].rhs.rhs.kT\n",
    "\n",
    "ui.fit('17644_A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes= plt.subplots(ncols=2, nrows=2, figsize=(10, 10))\n",
    "\n",
    "for i in ui.list_data_ids():\n",
    "    if i[-2:] == '_A':\n",
    "        ui.group_counts(i, 5)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    plt.sca(ax)\n",
    "    for i,j  in enumerate(plotorder[:3]):\n",
    "        ui.plot_fit(data['filestem'][j] + '_A', overplot=not(i==0), \n",
    "                    color=data['color'][j], clearwindow=False)\n",
    "        ui.plot_model_component(data['filestem'][j] + '_A', \n",
    "                                a_models[data['year'][j]].lhs * a_models[data['year'][j]].rhs.lhs,\n",
    "                                overplot=True, color=data['color'][j], linestyle=':')\n",
    "        ui.plot_model_component(data['filestem'][j] + '_A', \n",
    "                                a_models[data['year'][j]].lhs * a_models[data['year'][j]].rhs.rhs,\n",
    "                                overplot=True, color=data['color'][j], linestyle=':')\n",
    "    \n",
    "axes[0, 0].loglog()\n",
    "axes[0, 0].set_ylim(1e-5, 4e-2)\n",
    "axes[0, 1].semilogx()\n",
    "axes[1, 0].set_xlim(3.6, 4.2)\n",
    "axes[1, 1].set_xlim(6., 7.)\n",
    "axes[1, 1].legend(ax.get_lines()[::4], data['year'][plotorder[:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ui.list_data_ids():\n",
    "    if i[-2:] == '_A':\n",
    "        ui.group_counts(i, 5)\n",
    "\n",
    "def pl_13to17():\n",
    "    for i,j  in enumerate(plotorder[:3]):\n",
    "        ui.plot_fit(data['filestem'][j] + '_A', overplot=not(i==0), \n",
    "                    color=data['color'][j], clearwindow=False)\n",
    "        ui.plot_model_component(data['filestem'][j] + '_A', \n",
    "                                a_models[data['year'][j]].lhs * a_models[data['year'][j]].rhs.lhs,\n",
    "                                overplot=True, color=data['color'][j], linestyle=':')\n",
    "        ui.plot_model_component(data['filestem'][j] + '_A', \n",
    "                                a_models[data['year'][j]].lhs * a_models[data['year'][j]].rhs.rhs,\n",
    "                                overplot=True, color=data['color'][j], linestyle=':')\n",
    "    \n",
    "fig, axes = specplot(pl_13to17, figsize=(10, 8))\n",
    "axes[0].legend(axes[0].get_lines()[::4], data['year'][plotorder[:3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_models['2018'].rhs.lhs.Si.frozen = False\n",
    "a_models['2018'].rhs.lhs.Ca.frozen = False\n",
    "a_models['2018'].rhs.lhs.Fe.frozen = False\n",
    "\n",
    "abs1 = a_models['2018'].lhs\n",
    "xsv1 = a_models['2018'].rhs.lhs\n",
    "xsv2 = a_models['2018'].rhs.rhs\n",
    "\n",
    "ui.set_source('21176_A', abs1 * (xsv1 + xsv2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsv1.kT = 1.\n",
    "xsv2.kT = 5\n",
    "xsv1.kT.frozen = True\n",
    "xsv2.kT.frozen = False\n",
    "xsv1.norm = 1e-5\n",
    "xsv2.norm = 1e-5\n",
    "xsv2.norm.frozen=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ui.set_stat('chi2gehrels')\n",
    "ui.ungroup('21176_A')\n",
    "#ui.unsubtract('21176_A')\n",
    "ui.set_stat('cash')\n",
    "ui.notice(1.5, 10.)\n",
    "ui.ignore(None, 1.5)\n",
    "ui.ignore(10., None)\n",
    "print(ui.get_filter('21176_A'))\n",
    "ui.fit('21176_A')\n",
    "ui.group_counts('21176_A', 5)\n",
    "ui.notice(.5, 10.)\n",
    "ui.ignore(None, .5)\n",
    "ui.ignore(10., None)\n",
    "\n",
    "\n",
    "def pl_21176():\n",
    "    ui.plot_fit('21176_A', clearwindow=False)\n",
    "    ui.plot_model_component('21176_A', abs1 * xsv1, overplot=True)\n",
    "    ui.plot_model_component('21176_A', abs1 * xsv2, overplot=True)\n",
    "    \n",
    "fig, axes = specplot(pl_21176, figsize=(10, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for par in [abs1.nH, xsv1.Si, xsv1.Ca, xsv1.Fe, xsv1.norm, xsv2.kT, xsv2.norm]:\n",
    "    par.frozen = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsv1.kT.frozen = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsjeta = ui.xsvapec(name='xsjeta')\n",
    "abs2 = ui.xsphabs('abs2')\n",
    "ui.set_source('21176_A', xsjeta + abs1 * (xsv1 + xsv2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs2.nH = 0.1\n",
    "abs2.nH.frozen = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.set_method('moncar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ui.set_stat('chi2gehrels')\n",
    "ui.ungroup('21176_A')\n",
    "#ui.unsubtract('21176_A')\n",
    "ui.set_stat('cash')\n",
    "ui.notice(.5, 10.)\n",
    "ui.ignore(None, .5)\n",
    "ui.ignore(10., None)\n",
    "print(ui.get_filter('21176_A'))\n",
    "ui.fit('21176_A')\n",
    "ui.group_counts('21176_A', 5)\n",
    "ui.notice(.5, 10.)\n",
    "ui.ignore(None, .5)\n",
    "ui.ignore(10., None)\n",
    "\n",
    "def pl_21176():\n",
    "    ui.plot_fit('21176_A', clearwindow=False)\n",
    "    ui.plot_model_component('21176_A', abs1 * xsv1, overplot=True)\n",
    "    ui.plot_model_component('21176_A', abs1 * xsv2, overplot=True)\n",
    "    ui.plot_model_component('21176_A', xsjeta, overplot=True)\n",
    "    \n",
    "fig, axes = specplot(pl_21176, figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abspart = ui.xspcfabs(name='abspart')\n",
    "abspart.CvrFract.max = 1.\n",
    "ui.set_source('21176_A', abs1 * xsv1 + abspart * xsv2)\n",
    "\n",
    "abs1.nH = 19.4\n",
    "xsv1.kT = 0.6\n",
    "xsv1.Si = 8.9\n",
    "xsv1.Ca = 7.7\n",
    "xsv1.Fe = 1.5\n",
    "xsv1.norm = 0.015\n",
    "xsv2.kT = 4.3\n",
    "xsv2.norm = 0.00085\n",
    "abspart.nH = 61\n",
    "abspart.CvrFract = 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abspart = ui.xspcfabs(name='abspart')\n",
    "abspart.CvrFract.max = 1.\n",
    "ui.set_source('21176_A', abs1 * xsv1 + abspart * xsv2)\n",
    "\n",
    "ui.ungroup('21176_A')\n",
    "#ui.unsubtract('21176_A')\n",
    "ui.set_stat('cash')\n",
    "ui.notice(.5, 10.)\n",
    "ui.ignore(None, .5)\n",
    "ui.ignore(10., None)\n",
    "print(ui.get_filter('21176_A'))\n",
    "ui.fit('21176_A')\n",
    "ui.group_counts('21176_A', 3)\n",
    "ui.notice(.5, 10.)\n",
    "ui.ignore(None, .5)\n",
    "ui.ignore(10., None)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                      \n",
    "def pl_21176():\n",
    "    ui.plot_fit('21176_A', clearwindow=False)\n",
    "    ui.plot_model_component('21176_A', abs1 * xsv1, overplot=True)\n",
    "    ui.plot_model_component('21176_A', abspart * xsv2, overplot=True)\n",
    "    #ui.plot_model_component('21176_A', xsv1, overplot=True, color='k')\n",
    "    #ui.plot_model_component('21176_A', xsv2, overplot=True, color='k')\n",
    "    \n",
    "fig, axes = specplot(pl_21176, figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a_models['2019'].pars)):\n",
    "    a_models['2019'].pars[i].val = a_models['2018'].pars[i].val\n",
    "    a_models['2019'].pars[i].frozen = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_models['2019'].rhs.lhs.Ca = 1\n",
    "a_models['2019'].rhs.lhs.Si = 1\n",
    "a_models['2019'].rhs.rhs.Ca = 1\n",
    "a_models['2019'].rhs.rhs.Si = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pl_2019():\n",
    "    ui.plot_fit('2019_A', clearwindow=False)\n",
    "    ui.plot_model_component('2019_A', abs1 * xsv1, overplot=True)\n",
    "    ui.plot_model_component('2019_A', abs1 * xsv2, overplot=True)\n",
    "    \n",
    "fig, axes = specplot(pl_2019, figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_models['2019'].rhs.lhs.Si.frozen = True\n",
    "a_models['2019'].rhs.lhs.Ca.frozen = True\n",
    "a_models['2019'].rhs.lhs.Fe.frozen = False\n",
    "\n",
    "abs1 = a_models['2019'].lhs\n",
    "xsv1 = a_models['2019'].rhs.lhs\n",
    "xsv2 = a_models['2019'].rhs.rhs\n",
    "\n",
    "xsv1.kT.frozen = False\n",
    "xsv2.kT.frozen = False\n",
    "xsv1.norm.frozen = False\n",
    "xsv2.norm.frozen = False\n",
    "\n",
    "xsv1.Si = 1\n",
    "xsv1.Ca = 1\n",
    "xsv1.Fe = 5\n",
    "\n",
    "\n",
    "abspart = ui.xspcfabs(name='abspart')\n",
    "abspart.CvrFract.max = 1.\n",
    "\n",
    "for o in ['22323_A', '23100_A', '23101_A', '23102_A', '2019_A']:\n",
    "    ui.set_source(o, abs1 * xsv1 + abspart * xsv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.ungroup('2019_A')\n",
    "#ui.unsubtract('21176_A')\n",
    "ui.set_stat('cash')\n",
    "ui.notice(.5, 10.)\n",
    "ui.ignore(None, .5)\n",
    "ui.ignore(10., None)\n",
    "print(ui.get_filter('2019_A'))\n",
    "ui.fit('2019_A')\n",
    "ui.group_counts('2019_A', 3)\n",
    "ui.notice(.5, 10.)\n",
    "ui.ignore(None, .5)\n",
    "ui.ignore(10., None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pl_2019part():\n",
    "    ui.plot_fit('2019_A', clearwindow=False)\n",
    "    ui.plot_model_component('2019_A', abs1 * xsv1, overplot=True)\n",
    "    ui.plot_model_component('2019_A', abspart * xsv2, overplot=True)\n",
    "    \n",
    "fig, axes = specplot(pl_2019part, figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ui.list_data_ids():\n",
    "    if i[-2:] == '_A':\n",
    "        ui.group_counts(i, 5)\n",
    "\n",
    "def pl_13to19():\n",
    "    for i,j  in enumerate(plotorder):\n",
    "        ui.plot_fit(data['filestem'][j] + '_A', overplot=not(i==0), \n",
    "                    color=data['color'][j], clearwindow=False)\n",
    "        #ui.plot_model_component(data['filestem'][j] + '_A', \n",
    "        #                        a_models[data['year'][j]].lhs * a_models[data['year'][j]].rhs.lhs,\n",
    "        #                        overplot=True, color=data['color'][j], linestyle=':')\n",
    "        #ui.plot_model_component(data['filestem'][j] + '_A', \n",
    "        #                        a_models[data['year'][j]].lhs * a_models[data['year'][j]].rhs.rhs,\n",
    "        #                        overplot=True, color=data['color'][j], linestyle=':')\n",
    "    \n",
    "fig, axes = specplot(pl_13to19, figsize=(12, 6))\n",
    "axes[0].legend(axes[0].get_lines()[::2], data['year'][plotorder])\n",
    "axes[1].semilogy()\n",
    "axes[1].set_ylim(1e-4, 0.011)\n",
    "axes[0].set_xlim(None, 8.)\n",
    "axes[0].set_ylim(5e-5, None)\n",
    "fig.savefig('figout/spectraA13to19.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell keeps some older code used for annotate a spectrum. \n",
    "# I don't need that right now, but I also don't want to reinvent the wheel later.\n",
    "raise NotImplementedError\n",
    "\n",
    "\n",
    "fig.set_size_inches(12, 4)\n",
    "\n",
    "c = [l.get_c() for l in ax.get_lines()[1::2]]\n",
    "\n",
    "def annotate(text, pos, offset, color):\n",
    "    ax.annotate(text, color=color, fontsize='large',\n",
    "            xy=pos, xycoords='data',\n",
    "            xytext=offset, textcoords='offset points',\n",
    "            bbox=dict(boxstyle=\"round\", fc=\"0.9\"),\n",
    "            arrowprops=dict(arrowstyle=\"->\", color=color, linewidth=2,\n",
    "                            connectionstyle=\"angle,angleA=0,angleB=90,rad=10\"))\n",
    "\n",
    "annotate('Fe 6.7 keV', (6.7, 4e-3), (10, 30), c[3])\n",
    "annotate('Fe 6.62 keV', (6.62, 1.4e-2), (-10, 30), c[2])\n",
    "annotate('Ca XIX triplet', (3.88, 8e-3), (-10, 30), c[3])\n",
    "annotate('Ca XX', (4.1, 3e-3), (10, 30), c[3])\n",
    "annotate('Si XIII triplet', (1.85, 1.5e-2), (-10, 30), c[3])\n",
    "annotate('Si XIV', (2.0, 5e-3), (10, 30), c[3])\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "arrow = mpatches.Arrow(.6, 3e-3, 1, -2e-3, width=3e-3, color='0.6')\n",
    "ax.add_patch(arrow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FIP values from NIST\n",
    "# https://physics.nist.gov/cgi-bin/ASD/ie.pl?spectra=H-DS+i&units=1&at_num_out=on&el_name_out=on&shells_out=on&level_out=on&e_out=0&unc_out=on&biblio=on\n",
    "'''\n",
    "@Misc{NIST_ASD,\n",
    "author = {A.~Kramida and {Yu.~Ralchenko} and\n",
    "J.~Reader and {and NIST ASD Team}},\n",
    "HOWPUBLISHED = {{NIST Atomic Spectra Database\n",
    "(ver. 5.6.1), [Online]. Available:\n",
    "{\\tt{https://physics.nist.gov/asd}} [2018, November 30].\n",
    "National Institute of Standards and Technology,\n",
    "Gaithersburg, MD.}},\n",
    "year = {2018},\n",
    "}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018 flare vs non-flare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.load_data(100, 'data/Chandra/21176_A_grp.pi')\n",
    "ui.load_data(101, 'data/Chandra/21176_A_noflare_grp.pi')\n",
    "ui.load_data(102, 'data/Chandra/21176_A_flare_grp.pi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0, 3):\n",
    "    ui.ungroup(100 + i)\n",
    "    ui.ignore_bad(100 + i)\n",
    "\n",
    "ui.set_analysis(\"energy\")\n",
    "ui.ignore(None, 0.3)\n",
    "ui.ignore(9., None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set models for 2018 flare / non-flare times\n",
    "# same model, other normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0, 3):\n",
    "    ui.set_analysis(\"energy\")\n",
    "    ui.group_counts(100+i, 5)\n",
    "    ui.ignore(None, 0.3)\n",
    "    ui.ignore(9., None)\n",
    "\n",
    "    ui.plot_data(100+i, overplot=True)\n",
    "\n",
    "ax = plt.gca()\n",
    "#ax.loglog()\n",
    "#ax.set_xlim(.6, 8)\n",
    "#ax.set_ylim(1e-4, 0.02)\n",
    "ax.set_xlim(1, 7)\n",
    "ax.set_ylim(1e-4, 0.02)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(14, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
